{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96965a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path \n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from pdf_to_image import convert_pdf_to_image\n",
    "from page_finder import get_page_number\n",
    "from dockling import get_rmd_using_docling\n",
    "#from llm import get_response_from_llm\n",
    "from table_processor import process_markdown_table\n",
    "from load_to_csv import write_or_append_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf\n",
      "Converting: pdfs_to_be_processed\\0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 21:50:28,034 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-04 21:50:28,052 - INFO - Going to convert document batch...\n",
      "2026-01-04 21:50:28,055 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-04 21:50:28,072 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-04 21:50:28,078 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2026-01-04 21:50:28,089 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-04 21:50:28,102 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2026-01-04 21:50:28,140 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder not found.\n",
      "Pages to be processed: [1, 2, 3, 7, 8, 9, 10, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 21:50:28,351 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:50:30,297 - INFO - Auto OCR model selected easyocr.\n",
      "2026-01-04 21:50:30,313 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-04 21:50:30,324 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
      "2026-01-04 21:50:30,339 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:50:31,022 - INFO - Loading plugin 'docling_defaults'\n",
      "2026-01-04 21:50:31,025 - INFO - Registered table structure engines: ['docling_tableformer']\n",
      "2026-01-04 21:50:31,151 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:50:31,795 - INFO - Processing document page_1.jpg\n",
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2026-01-04 21:51:05,245 - INFO - Finished converting document page_1.jpg in 37.22 sec.\n",
      "2026-01-04 21:51:05,281 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-04 21:51:05,308 - INFO - Going to convert document batch...\n",
      "2026-01-04 21:51:05,312 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-04 21:51:05,316 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2026-01-04 21:51:05,319 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:07,098 - INFO - Auto OCR model selected easyocr.\n",
      "2026-01-04 21:51:07,099 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:07,529 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:08,327 - INFO - Processing document page_2.jpg\n",
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2026-01-04 21:51:47,255 - INFO - Finished converting document page_2.jpg in 41.97 sec.\n",
      "2026-01-04 21:51:47,321 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-04 21:51:47,349 - INFO - Going to convert document batch...\n",
      "2026-01-04 21:51:47,354 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-04 21:51:47,360 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2026-01-04 21:51:47,361 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:49,327 - INFO - Auto OCR model selected easyocr.\n",
      "2026-01-04 21:51:49,328 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:51,239 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 21:51:52,881 - INFO - Processing document page_3.jpg\n",
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2026-01-04 21:53:07,577 - INFO - Finished converting document page_3.jpg in 80.27 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 21:53:48,083 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response content: {\n",
      "  \"file_name\": \"0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf\",\n",
      "  \"revenue_this_quarter\": 3932.27,\n",
      "  \"revenue_previous_quarter\": 3753.31,\n",
      "  \"revenue_same_quarter_previous_year\": 11370.56\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 21:59:06,565 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response content: {\n",
      "  \"ebitda_this_quarter\": 251.25,\n",
      "  \"ebitda_previous_quarter\": 1176.46,\n",
      "  \"ebitda_same_quarter_previous_year\": 2122.54\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:04:50,884 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 22:11:18,206 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-04 22:11:18,269 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response content: {\n",
      "  \"net_profit_this_quarter\": 134.58,\n",
      "  \"net_profit_previous_quarter\": 2103.4,\n",
      "  \"net_profit_same_quarter_previous_year\": 2251.74\n",
      "}\n",
      "{'file_name': '0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf', 'revenue_this_quarter': 3932.27, 'revenue_previous_quarter': 3753.31, 'revenue_same_quarter_previous_year': 11370.56, 'ebitda_this_quarter': 251.25, 'ebitda_previous_quarter': 1176.46, 'ebitda_same_quarter_previous_year': 2122.54, 'net_profit_this_quarter': 134.58, 'net_profit_previous_quarter': 2103.4, 'net_profit_same_quarter_previous_year': 2251.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:11:18,277 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-04 22:11:18,301 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2026-01-04 22:11:18,309 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:11:22,142 - INFO - Auto OCR model selected easyocr.\n",
      "2026-01-04 22:11:22,146 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:11:23,106 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:11:24,213 - INFO - Processing document page_7.jpg\n",
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2026-01-04 22:12:23,094 - INFO - Finished converting document page_7.jpg in 64.91 sec.\n",
      "2026-01-04 22:12:23,204 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2026-01-04 22:12:23,246 - INFO - Going to convert document batch...\n",
      "2026-01-04 22:12:23,252 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
      "2026-01-04 22:12:23,270 - INFO - rapidocr cannot be used because onnxruntime is not installed.\n",
      "2026-01-04 22:12:23,274 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:12:25,690 - INFO - Auto OCR model selected easyocr.\n",
      "2026-01-04 22:12:25,691 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:12:26,278 - INFO - Accelerator device: 'cpu'\n",
      "2026-01-04 22:12:27,502 - INFO - Processing document page_8.jpg\n",
      "d:\\niithipeak_s1_backtest\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2026-01-04 22:13:30,677 - INFO - Finished converting document page_8.jpg in 67.47 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 0d472df2-2aea-4c2a-8ebe-ad04b21e5db7.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 22:14:16,062 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Define the directory path\n",
    "# Use \".\" for the current folder or provide a full path like \"C:/Users/Documents/PDFs\"\n",
    "folder_path = pathlib.Path(\"./pdfs_to_be_processed\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if folder_path.exists() and folder_path.is_dir():\n",
    "    # Iterate through all files ending in .pdf (case-insensitive)\n",
    "    for pdf_file in folder_path.glob(\"*.pdf\"):\n",
    "        # Define the directory and filename\n",
    "        md_directory = 'md_files'\n",
    "        md_filename = os.path.join(md_directory, 'output.md')\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(md_directory, exist_ok=True)\n",
    "\n",
    "        # Sample markdown content\n",
    "        markdown_content = \"\"\"\n",
    "        # My Output File\n",
    "\n",
    "        This file was created successfully!\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Write the file\n",
    "        with open(md_filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(markdown_content.strip() + '\\n')\n",
    "\n",
    "\n",
    "        print(f\"Processing: {pdf_file.name}\")\n",
    "        \n",
    "        # Example: Get the absolute path if you need to open it\n",
    "        #full_path = pdf_file.resolve()\n",
    "        #print(f\"Full Path: {full_path}\")\n",
    "        pdf_page_photos_path = \"./pdf_page_photos\"\n",
    "        pdf_path = os.path.join(folder_path, pdf_file.name)\n",
    "        convert_pdf_to_image(pdf_path , pdf_page_photos_path)\n",
    "\n",
    "        page_number = get_page_number(pdf_page_photos_path)\n",
    "        print(f\"Pages to be processed: {page_number}\")\n",
    "\n",
    "        #if page_number is not None:\n",
    "        #    current_page = 0\n",
    "\n",
    "        #    for i in page_number:\n",
    "        #        for page in Path(pdf_page_photos_path).glob(\"*.jpg\"):\n",
    "        #            current_page += 1\n",
    "        #            if current_page == i:\n",
    "        #                print(f\"------------------------------------------Processing page: {current_page}\")\n",
    "        #                get_rmd_using_docling(os.path.join(pdf_page_photos_path, page.name), \"./md_files\")\n",
    "        #                llm_json = get_response_from_llm(\"./md_files/output.md\", pdf_file.name)\n",
    "        #                print(llm_json)\n",
    "        #                write_or_append_csv(llm_json, \"financial_changes.csv\")\n",
    "\n",
    "\n",
    "        for i in page_number:\n",
    "            processing_photo = os.path.join(pdf_page_photos_path, f\"page_{i}.jpg\")\n",
    "            no_table = get_rmd_using_docling(\n",
    "                    processing_photo,\n",
    "                    \"./md_files\"\n",
    "                )\n",
    "            if no_table == \"no tables found\":\n",
    "                continue\n",
    "            else:\n",
    "                #llm_json = get_response_from_llm(\"./md_files/output.md\", pdf_file.name)\n",
    "                llm_json = process_markdown_table(\"./md_files/output.md\", pdf_file.name)\n",
    "                print(llm_json)\n",
    "                write_or_append_csv(llm_json, \"financial_changes.csv\")\n",
    "\n",
    "\n",
    "#\n",
    "#        page_numbers = set(page_number)  # faster lookup\n",
    "#        current_page = 0\n",
    "#\n",
    "#        for page in Path(pdf_page_photos_path).glob(\"*.jpg\"):\n",
    "#            current_page += 1\n",
    "#            if current_page in page_numbers:\n",
    "#                print(f\"------------------------------------------Processing page: {current_page}\")\n",
    "#                get_rmd_using_docling(\n",
    "#                    os.path.join(pdf_page_photos_path, page.name),\n",
    "#                    \"./md_files\"\n",
    "#                )\n",
    "#                llm_json = get_response_from_llm(\"./md_files/output.md\", pdf_file.name)\n",
    "#                print(llm_json)\n",
    "#                write_or_append_csv(llm_json, \"financial_changes.csv\")\n",
    "\n",
    "\n",
    "        # Deleting the folder after processing\n",
    "        try:\n",
    "            shutil.rmtree(pdf_page_photos_path)\n",
    "            shutil.rmtree(\"./md_files\")\n",
    "            #shutil.move(, destination_path)\n",
    "\n",
    "            #print(\"Folder and all its contents deleted successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {folder_path}. Reason: {e}\")\n",
    "\n",
    "        \n",
    "        shutil.move(pdf_file, \".\\processed_pdf's\")\n",
    "\n",
    "        time.sleep(7 * 60)\n",
    "        # Your logic here (e.g., extracting text, renaming, moving)\n",
    "        # ...\n",
    "else:\n",
    "    print(\"The specified folder does not exist.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d60d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a660996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niithipeak_s1_backtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
